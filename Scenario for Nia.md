# Scenario 1: Nia as a Sound Designer

Nia is a sound designer working in the automotive industry, where her responsibilities range from tuning in-vehicle acoustics to creating simple sound signals for specific situations that require user attention. Although Nia is focused on interactive sound creation, she does not deeply consider the user's situational context; she primarily works from ideas suggested by other teams like UX designers or marketers. Nia's musical background is informal, having studied music as a hobby and regularly engaging in activities like playing instruments and composing with MIDI software using sound libraries.

When tasked with creating sound signals for automotive applications, Nia needs to consider the cognitive flow of users, particularly how different chords interact and influence user attention. To support this logic-making process, Nia uses an AI-powered tool that helps her design a storyboard, select suitable chords, and assign them to the relevant phases. She starts by writing the overall theme of the storyboard and then needs to detail each phase. While Nia understands the purpose of this step, she finds it challenging to determine the perspectives from which these details should be written. To simplify the process, Nia typically inputs only the theme and the number of phases into the tool. The tool then generates a suitable question to initialise the communication with the AI system, taking the burden away from Nia to formulate precise queries. The AI system's outputs are task-oriented, considering cognitive flows and aligning well with the later steps of chord selection and assignment. Satisfied with the results, Nia sometimes seeks further clarification or asks additional questions about user experience-related details in the text prompt. She also likes the flexibility to add more boxes for additional phases and to include AI-generated images that represent each phase's theme. This step supports the creation of a series of storyboard and descriptions as a design journey, useful to share with her team and stakeholders.

Once the storyboard is saved, Nia moves on to the next step: selecting chords for the relevant phases. She first ticks the boxes where she wants to apply sound signals and then inputs the chosen chords for each phase. While Nia has basic knowledge of tonal music, such as chord types, she is less familiar with tonal functionality and differences between musical keys. When her team member Joon, who majored in classical music composition, is unavailable, Nia opts for the tool's feature to choose and explain keys and functions automatically. Nia appreciates being able to define each sound's function in plain language---using terms like “start”, “rising”, “peak”, or “end”---without focusing on harmonic details. The tool helps her translate this input into harmonic information, enabling the AI to offer options that meet her design objectives. Nia sometimes asks further questions and reflects on the AI system's suggestions, leveraging her basic knowledge of tonal principles to enhance her understanding. She occasionally uses the AI's note arrangement feature to fine-tune chord structures. After establishing the basic design logic in the storyboard and sound arrangement, Nia transitions to another MIDI software via the tool's connected API for sound creation and refinement.