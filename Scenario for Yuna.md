# Scenario 2: Yuna as a UX Designer

Yuna is a UX designer in the home appliance industry, primarily responsible for planning user experiences across various products, including those with multimodal interfaces. Though her main focus is on visual displays and the overall user experience, she occasionally contributes to auditory interface design projects. In these cases, Yuna lays the groundwork by providing design foundations before sound designers create the actual sounds. Yuna's musical background is very basic; she had some exposure to music as a child, but her engagement with music is limited to everyday listening and occasional karaoke. When working on a project involving auditory interfaces, such as creating simple sound signals for different situations, Yuna focuses on the cognitive aspects of users based on task flow within the storyboard. Though Yuna understands how different chords interact and influence user attention conceptually, she is not familiar with the music theoretical details.

To effectively design auditory interfaces, Yuna uses an AI-powered tool that helps her create a storyboard, select suitable chords, and assign them to relevant phases. She begins by writing the overall theme of the storyboard and then detailing each phase. The tool allows her to divide a phase into more specific sub-phases when needed. Given her background in human factors, Yuna draws on her extensive experience to detail phases that support end-users on every step of the process. When designing novel multimodal interfaces, she often uses the AI features to generate potential alternatives for each phase, repeating this process iteratively to refine the phases and overall storyboards, including descriptive images.

Once the storyboard is complete, Yuna moves on to the chord decision step. Her role does not require her to be specific about sound materialisation, but her ideas for the sound design must be understandable to other practitioners, especially sound designers. She first selects the boxes where sound signals are needed, often focusing on detailed divisions within larger phases, and then inputs suitable chords for the selected phases. Lacking musical knowledge, Yuna frequently relies on the tool's recommendation feature, assigning harmonic functions for each signal using plain language input and initialising communication with the AI system. For key selection, Yuna opts for the simplest settings and follows the “any” option, resulting in a random tonal structure. She finds it helpful that the tool allows her to initiate communication with the AI system aligned with her design purpose. Once the communication begins, she can refine the low-fidelity sounds through continuous querying. Among the suggested chords and keys, Yuna typically selects one of the options and uses the tool's note arrangement feature to explore different note combinations. She listens to all the options provided by the AI system to understand their sound intuitively, which proves valuable during meetings with sound designers. Once she is satisfied with the progress, she enters the storyboard immersive feature which also shows the musical arrangement for each phase, Yuna often uses this mode to present her progress and sound design rationale to the team.